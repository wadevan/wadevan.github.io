<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://wadevan.github.io/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 25 Mar 2018 21:06:15 +0800</lastBuildDate>
    
        <atom:link href="https://wadevan.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://wadevan.github.io/about/</link>
      <pubDate>Sun, 25 Mar 2018 21:06:15 +0800</pubDate>
      
      <guid>https://wadevan.github.io/about/</guid>
      
        <description>

&lt;h3 id=&#34;关于我&#34;&gt;关于我&lt;/h3&gt;

&lt;p&gt;Record Like a Painter&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>0x protocol分析</title>
      <link>https://wadevan.github.io/2018/0x-protocol%E5%88%86%E6%9E%90/</link>
      <pubDate>Fri, 05 Jan 2018 19:20:05 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2018/0x-protocol%E5%88%86%E6%9E%90/</guid>
      
        <description>

&lt;p&gt;0x protocol是当前币价比较高的一种token exchange协议。提供了一种以太坊网络中token交换的去中心化解决方案。&lt;/p&gt;

&lt;h2 id=&#34;协议概述&#34;&gt;协议概述&lt;/h2&gt;

&lt;p&gt;下图为0x protocol的off-chain order转发和on-chain settlement的逻辑图。&lt;br /&gt;
&lt;img src=&#34;https://wadevan.github.io/images/0xprotocol_1.png&#34; alt=&#34;图1. 0x protocol 整体逻辑图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图中灰色的矩形和圆形分别代表以太坊上的智能合约和账户。具体的逻辑：
1. maker同意DEX(去中心化交易所合约)获取他们关于Token A的信息。
2. Maker创建一笔关于Token A兑换为Token B的订单，并且声明了期望的交易rate和过期时间。将以上订单签名。
3. Maker 通过网络传输层将此订单广播
4. Taker接收到这笔订单，并且决定来完成此项订单。&lt;br /&gt;
5. Taker同意DEX来获取他的关于Token B的信息。
6. Taker提交maker的那条以签名的order到DEX合约。
7. DEX合约认证maker的签名，验证通过后，然后将两者的Token按照拟定的rate进行交换。&lt;/p&gt;

&lt;p&gt;其中，关于上述的&lt;code&gt;操作3&lt;/code&gt;和&lt;code&gt;操作4&lt;/code&gt;off-chain的行为，0x protocol的网络传输层和会话层以及应用层来负责Order的relay，展示，以及推送。当然，用户也可以将签好名的order通过email，twitter等方式广播出去，Taker一旦获取之后，将order发送至DEX合约即可完成交易。&lt;/p&gt;

&lt;h2 id=&#34;消息格式&#34;&gt;消息格式&lt;/h2&gt;

&lt;p&gt;0x protocols的order的消息格式定义为：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Data Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;DEX 地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;maker&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;order的创建者&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;taker&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;接单者地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;token A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;ERC20 token 地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;token B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;ERC20 token 地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;value A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;token A 的数量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;value B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;token B 的数量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;expiration&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;过期时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;v&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint8&lt;/td&gt;
&lt;td&gt;ECDSA 签名参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;r&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;bytes32&lt;/td&gt;
&lt;td&gt;ECDSA 签名参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;s&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;bytes32&lt;/td&gt;
&lt;td&gt;ECDSA 签名参数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;order广播&#34;&gt;Order广播&lt;/h2&gt;

&lt;p&gt;0x protocols采用了off-chain的模式来传送order，用户可以自发的广播自己的订单。
同时，0x protocol 设计了一个简单的转发order的机制，maker也可以通过寻找relayer来上传自己的order。
其中relayer，maker，taker三者的关系如下：
&lt;img src=&#34;https://wadevan.github.io/images/0xprotocol_2.png&#34; alt=&#34;relayer 转发order逻辑图&#34; /&gt;
协议提供了feeRecipient来促进order的转发，具体order广播逻辑如下：
1. Relayer公布一个fee的schedule和收款地址
2. Maker创建order，配置relayer的fee和地址，然后签名
3. Relayer收到订单之后，校验订单，然后发布在自己的order book中
4. Takers 通过order book，选中合适的order，然后签名发送到以太坊的（DEX）智能合约地址上&lt;/p&gt;

&lt;p&gt;上述order的数据格式如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Data Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;DEX 地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;maker&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;order的创建者&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;taker&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;接单者地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;token A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;ERC20 token 地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;token B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;ERC20 token 地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;value A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;token A 的数量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;value B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;token B 的数量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;expiration&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;过期时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;v&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint8&lt;/td&gt;
&lt;td&gt;ECDSA 签名参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;r&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;bytes32&lt;/td&gt;
&lt;td&gt;ECDSA 签名参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;s&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;bytes32&lt;/td&gt;
&lt;td&gt;ECDSA 签名参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;feeRecipient&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;address&lt;/td&gt;
&lt;td&gt;relayer的地址&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;feeA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;Maker需要的费用&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;feeB&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;uint256&lt;/td&gt;
&lt;td&gt;Taker需要的费用&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;##智能合约
0x protocols的DEX智能合约其中的一个能力是验证订单的合法性，通过使用ecrecover func 验证签名，来判断order的合法性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;address publicKey = ecrecover( hash, signature( hash ) );
                           if ( publicKey != maker ) throw;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除此之外，DEX合约存储了已经filled的订单的reference，来阻止一个order被filled多次。协议将order通过Keccak SHA3算法映射到一个32byte的hash中，然后作为key存储。
同时，0x protocol协议也增加了一个valueFill字段，来完成订完部分完成的功能。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;0x protocols 采用onchain的DEX协议完成token的交易，保证token交易的安全，将order book的相关业务逻辑转交给各个要接入0x protocols的应用层。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>以太坊交易池逻辑分析</title>
      <link>https://wadevan.github.io/2017/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%BA%A4%E6%98%93%E6%B1%A0%E9%80%BB%E8%BE%91%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 07 Dec 2017 17:23:13 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2017/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%BA%A4%E6%98%93%E6%B1%A0%E9%80%BB%E8%BE%91%E5%88%86%E6%9E%90/</guid>
      
        <description>&lt;p&gt;发送一笔以太坊网络转账交易，除了成功之外，会遇到各种问题，比如发送的一笔交易在etherscan中查不到，或者查到是pending的状态，后来过了几个小时消失了，这些都与节点的交易池的处理逻辑相关，而交易池的逻辑可以有各种实现，目前官方的go-ethereum 的交易池逻辑如下。&lt;/p&gt;

&lt;p&gt;当一条交易进入挖矿节点的交易池(tx_pool)时，此节点会做出以下逻辑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过判断交易hash，当这条交易已经在节点的交易池里面时，就会丢弃掉当前收到的这一个交易。
如果是一个全新的hash，就会更具共识协议，对这一条交易做基本的验证。验证包括：长度，value，是否溢出当前区块的gaslimit，Nonce值，转账提供的gas大小是否太小等。
如果验证不通过就会返回相应的错误代码。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当验证通过的话，需要根据当前交易池的状态来决定，如果交易池满了的话，那么判断当前的转账交易提供的gas是否高于交易池里当前提供gas最低的那条交易。如果低了，就返回错误&lt;code&gt;ErrUnderpriced&lt;/code&gt;，这是返回的错误经常在etherscan中看到。如果当前交易提供的gas值高的话，那么就剔除掉了那一条提供最低gas的转账交易，为当前交易腾出空间。这种情况发生之后，往往在etherscan中会观察到正在pending的交易消失了，找不到了。（也有很大机率依然能够查到pending的交易，原因是etherscan连接了很多节点，每个节点的交易池的状态都是不一样的，那条被踢出的交易在别的节点依然pending）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果当前交易的Nonce已经在交易池里面了，说明了这个用户想替代之前发出的相同的Nonce的交易。这时节点会判断当前交易的gas是否高出上一条相同Nonce的交易gas某一个阈值（比如默认的是10%）。如果高出了，那么就会剔除之前的那个交易，新的交易就会保留，如果没有高出，当前的交易就会返回失败。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上逻辑都通过了，那么此条交易便成功存在交易池中等待打包，当然也有可能会被别的高gas的转账交易剔除的概率。&lt;/p&gt;

&lt;p&gt;总结，如果你发送了一笔交易碰巧赶上了以太坊网络拥堵，那么你的交易很有可能发送失败。原因是所有的挖矿节点都不接受这么低的gas交易了，或者你本来在交易池中，被剔除了。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>ethereum rpc 调用分析</title>
      <link>https://wadevan.github.io/2017/ethereum-rpc-%E8%B0%83%E7%94%A8%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 07 Oct 2017 17:24:31 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2017/ethereum-rpc-%E8%B0%83%E7%94%A8%E5%88%86%E6%9E%90/</guid>
      
        <description>

&lt;p&gt;以太坊以JSON RPC的方式提供API service。本文将从go-ethereum源码中挖掘服务端如何提供JSON RPC 服务。&lt;/p&gt;

&lt;h2 id=&#34;服务端启动rpc-server&#34;&gt;服务端启动rpc server&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;➜  go-ethereum git:(master) ✗ tree -d -L 1
├── cmd
    ├── geth
        ├── main.go
├── internal
    ├── ethapi
        ├── api.go
├── node
├── rpc
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;go-ethereum的代码很多，单从发起一笔转账这样一个api而言，geth节点涉及的代码相对简单。&lt;br /&gt;
首先，&lt;code&gt;cmd/geth/main.go&lt;/code&gt;是整个geth节点的entrypoint，main函数会实例化一个全功能的节点:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func geth(ctx *cli.Context) error {
	node := makeFullNode(ctx)
	startNode(ctx, node)
	node.Wait()
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实例化之后，将调用&lt;code&gt;node/node.go&lt;/code&gt;中的Start方法，来配置node相应的服务, 然后启动，等到所有的服务启动完成之后，节点开启RPC服务，根据config将相应的服务注册到RPC服务的白名单中:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (s *Server) RegisterName(name string, rcvr interface{}) error {
    ...
    methods, subscriptions := 
    suitableCallbacks(rcvrVal, svc.typ)
    ...
    svc.name = name
    svc.callbacks, svc.subscriptions = methods, subscriptions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述方法将一个service中的可以rpc调用的method存储到server的map中。&lt;br /&gt;
go-ethereum节点的rpc提供了四种能力的rpc，以HTTP为例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (n *Node) startHTTP(endpoint string, apis []rpc.API, modules []string, cors []string) error {
    // Register all the APIs exposed by the services
    ...
    // All APIs registered, start the HTTP listener
    var (
        listener net.Listener
        err      error
    )
    if listener, err = net.Listen(&amp;quot;tcp&amp;quot;, endpoint); err != nil {
        return err
    }
    go rpc.NewHTTPServer(cors, handler).Serve(listener)
    ...
｝
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;geth节点将监听端口，默认是8545，然后开启HTTPServer，等待http rpc请求。&lt;/p&gt;

&lt;h2 id=&#34;http-rpc-请求响应流程&#34;&gt;HTTP RPC 请求响应流程&lt;/h2&gt;

&lt;p&gt;一个标准的&lt;a href=&#34;http://www.jsonrpc.org/specification&#34;&gt;HTTP RPC请求&lt;/a&gt;如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST --data \
&#39;{&amp;quot;jsonrpc&amp;quot;:&amp;quot;2.0&amp;quot;,&amp;quot;method&amp;quot;:&amp;quot;eth_sendRawTransaction&amp;quot;,&amp;quot;params&amp;quot;:[&amp;quot;0xd46e8dd67c5d32be8d&amp;quot;],&amp;quot;id&amp;quot;:1}&#39; http://localhost:8545
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要&lt;code&gt;jsonrpc&lt;/code&gt;, &lt;code&gt;method&lt;/code&gt;, &lt;code&gt;params&lt;/code&gt;和&lt;code&gt;id&lt;/code&gt;构成request body。当我们的geth节点的rpc server监听到新的request到来时，将会:
1. 实例化一个NewJSONCodec编码器。
2. 通过编码器来将request转换成jsonRequest，然后获取service_name和service_method以及params。
3. 通过service_name 和service_method，可以找到当时注册的rpc服务。
4. 通过反射方式运行rpc服务&lt;code&gt;reply := req.callb.method.Func.Call(arguments)&lt;/code&gt;，得到method的返回值
5. 利用编码器将返回值json序列化，然后返回&lt;code&gt;codec.Write(response)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;针对一个转账交易的话，我们得知service_name 是eth，service_method是sendRawTransaction，其方法在&lt;code&gt;internal/api.go&lt;/code&gt;中。运行&lt;code&gt;reply := req.callb.method.Func.Call(arguments)&lt;/code&gt;之后我们得到的reply是一个common.Hash对象，然后通过json序列化我们得到的结果是TxnHash的字符串。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;id&amp;quot;:1,
  &amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,
  &amp;quot;result&amp;quot;: &amp;quot;0xe670ec64341771606e55d6b4ca35a1a6b75ee3d5145a99d05921026d1527331&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS - 内容寻址的版本化点对点文件系统(草稿3) 翻译</title>
      <link>https://wadevan.github.io/2017/ipfs-%E5%86%85%E5%AE%B9%E5%AF%BB%E5%9D%80%E7%9A%84%E7%89%88%E6%9C%AC%E5%8C%96%E7%82%B9%E5%AF%B9%E7%82%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E8%8D%89%E7%A8%BF3-%E7%BF%BB%E8%AF%91/</link>
      <pubDate>Tue, 26 Sep 2017 16:18:08 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2017/ipfs-%E5%86%85%E5%AE%B9%E5%AF%BB%E5%9D%80%E7%9A%84%E7%89%88%E6%9C%AC%E5%8C%96%E7%82%B9%E5%AF%B9%E7%82%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E8%8D%89%E7%A8%BF3-%E7%BF%BB%E8%AF%91/</guid>
      
        <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/ipfs/ipfs/blob/master/papers/ipfs-cap2pfs/ipfs-p2p-file-system.pdf?raw=true&#34;&gt;IPFS - Content Addressed, Versioned, P2P File System (draft 3)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;

&lt;p&gt;星际文件系统是一个点对点分布式文件系统, 旨在使用相同的文件系统连接所有的计算设备。在某种情形下，IPFS很类似Web，不过IPFS可以被看作一个独立的使用Git仓库来交换对象的BitTorrent集群。换句话说，IPFS提供了一个高吞吐量的以内容可寻址的块存储模型，具有内容寻址的超链接。这便形成了广义的Merkle DAG数据结构，这种数据结构可以构建成一个文件版本系统，区块链，甚至一个永久性Web。IPFS使用分布式哈希表，激励化的块交易模型和自我认证的命名空间。IPFS没有单独的故障节点，节点之间不需要完全信任基础。&lt;/p&gt;

&lt;h2 id=&#34;1-介绍&#34;&gt;1.介绍&lt;/h2&gt;

&lt;p&gt;关于构建全球分布式文件系统，已经有许多尝试。一些系统已经取得了重大的成功， 而一些却完全失败了。在学术尝试中， AFS[6] 就是成功的例子，并且得到广泛的应用。 然而，其他的[7, ?] 却没有成功。学术界之外，最成功的系统是面向音视频媒体的点对点文件共享系统。 最值得注意的是， Napster, KaZaA 和BitTorrent[2] 部署的文件分发系统可以支持1亿用户同时在线。即使今天， BitTorrent 也维持着每天千万节点的活跃数[16]。&lt;br /&gt;
相比学术文件系统，这些应用获得了更多的用户和文件分发，然而这些应用并没有被设计为基础设施。虽然这些应用已经取得了成功的回报，但目前还没有出现为全球提供低延迟和分散式分发的广义的文件系统。&lt;br /&gt;
也许是因为HTTP这样“足够好“的系统已经存在。到目前为止，HTTP作为最成功的“分布式文件系统“的协议已经大量部署，再与浏览器相结合，具有巨大的技术和社会影响力。它已经成为互联网传输文件的事实标准。然而，他没有采用最近15年的发明的数十种先进的文件分发技术。 从一方面讲， 由于向后兼容的限制和当前模式的强烈投入， 进化目前的Web基础架构几乎不可能。但从另一个角度看，自从出现了HTTP，新的协议已经出现并被广泛使用。目前的难题缺是升级设计：不会降低用户体验情况下引入新功能，以增强目前的HTTP Web。&lt;br /&gt;
长期使用HTTP的业界已经消失了，因为移动小文件是非常便宜，即使是具有大量流量的小型组织。但是，随着新的挑战，我们正在进入数据分发的新时代：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;（a）托管和分发PB级数据集&lt;/li&gt;
&lt;li&gt;（b）计算跨组织的大数据&lt;/li&gt;
&lt;li&gt;（c）按需量或实时媒体流量大规模高清晰度定义&lt;/li&gt;
&lt;li&gt;（d）大规模数据集的版本化和链接&lt;/li&gt;
&lt;li&gt;（e）防止重要文件的意外消失等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;许多这些可以归结为“大量数据，无处不在”。由于关键功能和带宽问题，我们已经放弃了不同数据的HTTP分发协议。下一步是使它们成为一部分的Web本身。&lt;/p&gt;

&lt;h2 id=&#34;2-背景&#34;&gt;2.背景&lt;/h2&gt;

&lt;p&gt;本节回顾了IPFS所采用的点对点系统的重要技术特性。&lt;/p&gt;

&lt;h3 id=&#34;2-1-分布式哈希表&#34;&gt;2.1 分布式哈希表&lt;/h3&gt;

&lt;p&gt;分布式哈希表(DHTs)广泛的使用于定位和维持点对点系统的元数据。例如BitTorrent的MainlineDHT技术跟踪torrent集群的对等节点。&lt;/p&gt;

&lt;h4 id=&#34;2-1-1-kademlia-dht&#34;&gt;2.1.1 Kademlia DHT&lt;/h4&gt;

&lt;p&gt;Kademlia[10] 是一个广泛流行的DHT，提供了一下特点:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;大规模网络下高效查询：查询平均访问O(log2N)节点。(例如，1000万节点的网络需要20跳查询)&lt;/li&gt;
&lt;li&gt;低协调开销：优化控制消息发送到其他节点的数量。&lt;/li&gt;
&lt;li&gt;使用长时间在线节点来抵抗各种攻击。&lt;/li&gt;
&lt;li&gt;广泛使用于点对点应用中，包括Gnutella和BitTorrent，形成了超过2000万个节点的网络[16]。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-1-2-coral-dsht&#34;&gt;2.1.2 Coral DSHT&lt;/h4&gt;

&lt;p&gt;虽然一些对等文件系统直接在DHT中存储数据块，“不应该存储在节点的数据存储在节点会浪费存储和带宽”[5]。Coral DSHT通过以下三种方式扩展了Kademlia：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Kademlia将值存储在距离其key最接近(使用XOR-distance)的节点中。这不考虑应用数据的局部性，忽略“远处”可能已经拥有此数据的节点，并强制“最近”节点存储它，无论它们是否需要。这将浪费了大量的存储和带宽。相反, Coral 存储了地址， 该地址的对等节点可以提供相应的数据块。&lt;/li&gt;
&lt;li&gt;Coral将DHT API的get_value(key)换成了get_any_values(key)（DSHT中的“sloppy”）。这将依旧工作，是因为Coral用户只需要一个（工作）的对等节点，而不是完整的列表。作为回报，Coral可以仅将子集分配到“最近”的节点，避免热点（当密钥变得流行时，重载所有最近的节点）。&lt;/li&gt;
&lt;li&gt;另外，Coral根据区域和大小组织了一个称为clusters的独立DSHT层次结构。这使得节点首先查询其区域中的对等体，“查找附近的数据而不查询远程节点”[5]并大大减少查找的延迟。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-1-3-s-kademlia-dht&#34;&gt;2.1.3 S/Kademlia DHT&lt;/h4&gt;

&lt;p&gt;S/Kademlia[1]使用以下方式扩展了Kademlia来防止恶意的攻击:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;S/Kad 提供了方案来保证NodeId的生成，防止Sybill攻击。它需要节点产生PKI公私钥对，从中获得他们的Identity，并彼此间签名。一个方案使用POW工作量证明，使得生成Sybills攻击的成本高昂。&lt;/li&gt;
&lt;li&gt;S/Kad 节点在不相交的路径上查找， 即使网络中存在大量的不诚实节点，也能确保诚实节点可以互相链接。即使网络中存在一半的不诚实节点，S/Kad 也能达到85%的成功率。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-2块交换-bittorrent&#34;&gt;2.2块交换 - BitTorrent&lt;/h3&gt;

&lt;p&gt;BitTorrent[3] 是一个非常成功的点对点共享文件系统，它可以在存在不信任的对等节点（群集）的协作网络中分发各自的文件数据片。从BitTorrent和它的生态系统的关键特征中 IPFS得到启示如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;BitTorrent的数据交换协议使用了一种bit-for-tat的激励策略， 可以奖励对其他节点做出贡献的节点，惩罚只吸取对方资源的节点&lt;/li&gt;
&lt;li&gt;BitTorrent对等节点跟踪文件的可用性，优先发送稀有片段。这减轻了seeds节点的负担， 让non-seeds节点有能力互相交易。&lt;/li&gt;
&lt;li&gt;对于一些剥削带宽共享策略， BitTorrent的标准tit-for-tat策略是非常脆弱的。 然而，PropShare[8]是一种不同的对等节点带宽分配策略， 可以更好的抵制剥削战略， 提高群集的表现。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-3版本控制系统-git&#34;&gt;2.3版本控制系统 - Git&lt;/h3&gt;

&lt;p&gt;版本控制系统提供了对随时间变化的文件进行建模的设施，并有效地分发不同的版本。流行版本控制系统Git提供了强大的Merkle DAG对象模型，以分布式友好的方式捕获对文件系统树的更改。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;不可更改的对象表示文件（blob），目录（tree）和更改（commit）。&lt;/li&gt;
&lt;li&gt;对内容加密哈希，让对象可寻址。&lt;/li&gt;
&lt;li&gt;links到其他对象是嵌入的，形成一个Merkle DAG。这提供了很多有用的完整和work-flow属性。&lt;/li&gt;
&lt;li&gt;很多版本元数据（分支，标示等）都只是指针引用，因此创建和更新的代价都小。&lt;/li&gt;
&lt;li&gt;版本改变只是更新引用或者添加对象。&lt;/li&gt;
&lt;li&gt;分布式版本改变对其他用户而言只是转移对象和更新远程引用。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-4自验证文件系统-sfs&#34;&gt;2.4自验证文件系统 - SFS&lt;/h3&gt;

&lt;p&gt;SFS[12,11]提出了两个引人注目的实现（a）分布式信任链，和（b）平等共享的全局命名空间。SFS引入了一种建构自我认证文件系统的技术：使用以下格式&lt;code&gt;/sfs/&amp;lt;Location&amp;gt;:&amp;lt;HostID&amp;gt;&lt;/code&gt;寻址远程文件系统，Location是服务器网络地址，并且: &lt;code&gt;HostID = hash(public_key || Location)&lt;/code&gt;
因此SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制。&lt;/p&gt;

&lt;h2 id=&#34;3-ipfs设计&#34;&gt;3.IPFS设计&lt;/h2&gt;

&lt;p&gt;IPFS是一个对等系统，没有节点拥有特权。IPFS节点在本地存储IPFS对象。节点之间彼此连接并且传送对象。IPFS协议根据不同的功能划分成以下子协议栈:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;身份 - 管理节点的创建和认证。&lt;/li&gt;
&lt;li&gt;网络 - 通过可配置化的不同的底层网络协议，管理节点之间连接。&lt;/li&gt;
&lt;li&gt;路由 - 维护定位特定对等节点和对象的信息表。应对本地和远端查询。默认是DHT，可以替换。&lt;/li&gt;
&lt;li&gt;交换 - 一个新奇的块交换协议(BitSwap)，用来管理块分发效率, 模拟市场, 轻微刺激数据复制。交易策略可以替换。&lt;/li&gt;
&lt;li&gt;对象 - 一个对应链接的以内容寻址的不可变的Merkle DAG对象。可以表示任意数据结构，例如，文件层级结构和通信系统。&lt;/li&gt;
&lt;li&gt;文件 - 受Git启发的文件版本层级系统&lt;/li&gt;
&lt;li&gt;命名 - 自我认证的可变命名系统&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这些子系统不是独立的；它们集成在一起，特性互相使用。然而分开描述他们依然是有用的，构建自底而上的协议栈。
符号：以下数据结构和方法都是Go语言语法。&lt;/p&gt;

&lt;h3 id=&#34;3-1-身份&#34;&gt;3.1 身份&lt;/h3&gt;

&lt;p&gt;节点被NodeId标识，是通过S/Kademlia’s的静态加密难题[1]创建的公钥的加密散列。节点存储他们的公私钥(密码加密)。用户可以在每次启动时都实例一个新的节点标识，不过会丢失之前拥有的网络利益。节点激励措施保持不变。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type NodeId Multihash
type Multihash []byte
//self-describing cryptographic hash digest
type PublicKey []byte
type PrivateKey []byte
//self-describing keys

type Node struct {
    NodeId NodeID
    PubKey PublickKey
    PriKey PrivateKey
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基于S/Kademlia创建IPFS身份标识:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;difficulty = &amp;lt;integer parameter&amp;gt;
n = Node{}
do{
    n.PubKey, n.PrivaKey = PKI.genKeyPair()
    n.NodeId = hash(n.PubKey)
    p = count_preceding_zero_bits(hash(n.NodeId)
} while (p &amp;lt; difficulty)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一次建立连接时，对等节点之间交换公钥，校验:&lt;code&gt;hash(other.PublicKey) equals other.NodeId&lt;/code&gt;。如果不相等，连接中断。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;加密函数须知&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相对于将系统锁定在一些特殊的方法集，IPFS更倾向自我描述值。哈希摘要值以multihash形式存储，其头部包括使用的哈希函数说明和以字节为单位的摘要长度。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;function code&amp;gt;&amp;lt;digest length&amp;gt;&amp;lt;digest bytes&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这允许系统来(a)选择最佳函数(安全性和速度性能) (b)随着方法选项的更新而进化，自我描述值允许使用不同参数选项兼容。&lt;/p&gt;

&lt;h3 id=&#34;3-2-网络&#34;&gt;3.2 网络&lt;/h3&gt;

&lt;p&gt;IPFS节点通过潜在的广义网络和IPFS网络中的上百个节点定期通信。IPFS网络栈特性:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;传输层: IPFS可以使用任何传输层协议，最好符合WebRTC DataChannels&lt;a href=&#34;为了浏览器联通性&#34;&gt;?&lt;/a&gt;或者uTP(LEDBAT [14])。&lt;/li&gt;
&lt;li&gt;可靠性: IPFS所依赖的底层网络不能保证的可靠性的话，便使用uTP (LEDBAT [14])或者SCTP [15]来保证可靠性。&lt;/li&gt;
&lt;li&gt;连通性: IPFS同样使用ICE NAT遍历技术[13]。&lt;/li&gt;
&lt;li&gt;完整性: 提供使用哈希校验和来检验消息的完整性&lt;/li&gt;
&lt;li&gt;确定性: 提供使用发送者公钥的HMAC来核查消息的真实性&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-1-对等网络地址须知&#34;&gt;3.2.1 对等网络地址须知&lt;/h4&gt;

&lt;p&gt;IPFS可以使用任意网络连接。他不依赖IP并且不假设已经获取IP。这使得IPFS可以在覆盖网络中使用。IPFS以multiaddr字节字符串形式保存地址，以供给底层网络使用。multiaddr提供了一种地址和协议的描述方式，并且提供了封装格式。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# an SCTP/IPv4 connection
/ip4/10.20.30.40/sctp/1234/
# an SCTP/IPv4 connection proxied over TCP/IPv4
/ip4/5.6.7.8/tcp/5678/ip4/1.2.3.4/sctp/1234/
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-3-路由&#34;&gt;3.3 路由&lt;/h3&gt;

&lt;p&gt;IPFS节点需要一个路由系统来(a)寻找别的节点的网络地址，(b)寻找节点的服务对象。IPFS通过使用一个基于S/Kademlia和Coral的DSHT来解决上述问题，具体的特性详见2.1。对象的大小和IPFS使用的模式方面，类似于Coral[5]和Mainline[16]，因此IPFS的DHT根据对象存储时的大小对其进行区分。小的值(小于等于1KB)直接存储在DHT中。对于大的值，DHT中存储的是具体存储不同区块的对等节点的NodeIds的引用。
DSHT的接口如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type IPFSRouting interface {
    FindPeer(node NodeId)
    // gets a particular peer’s network address
    SetValue(key []bytes, value []bytes)
    // stores a small metadata value in DHT
    GetValue(key []bytes)
    // retrieves small metadata value from DHT
    ProvideValue(key Multihash)
    // announces this node can serve a large value
    FindValuePeers(key Multihash, min int)
    // gets a number of peers serving a large value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意: 不用的路由系统中需要不同的路由实例(广泛网络中使用DHT, 局域网络中使用静态HT)。因此IPFS路由系统可以根据用户需求来替换。只要接口保持匹配，系统便能正常运行。&lt;/p&gt;

&lt;h3 id=&#34;3-4-块交换-bitswap协议&#34;&gt;3.4 块交换 - BitSwap协议&lt;/h3&gt;

&lt;p&gt;受到BitTorrent 的启发，IPFS 中的BitSwap协议通过对等节点间交换数据块来分发数据的。像BitTorrent一样， 对等节点在换取想要的块数据是以交换自己所拥有的块数据为前提的。和BitTorrent协议不同的是， BitSwap不局限于一个torrent文件中的数据块。BitSwap 协议中存在一个永久的市场。 这个市场包括各个节点可以获取的所有块数据，而不管在意这些块是哪些文件中的一部分。这些快数据可能来自文件系统中完全不相关的文件。 这个市场是由所有的节点组成的。
虽然易货系统的概念意味着可以创建虚拟货币，但这将需要一个全局分类账本来跟踪货币的所有权和转移。这可以实施为BitSwap策略，并将在未来的论文中探讨。
在基本情况下，BitSwap节点必须以块形式彼此提供直接的值。只有当跨节点的块的分布是互补的时候，各取所需的时候，这才会工作的很好。 通常情况并非如此，在某些情况下，节点必须为自己的块而工作。 在节点没有其对等节点所需的（或根本没有的）情况下，它会更低的优先级去寻找对等节点想要的块。这会激励节点去缓存和传播稀有片段， 即使节点对这些片段不感兴趣。&lt;/p&gt;

&lt;h4 id=&#34;3-4-1-bitswap信用&#34;&gt;3.4.1 BitSwap信用&lt;/h4&gt;

&lt;p&gt;这个协议必须带有激励机制， 去激励节点去seed 其他节点所需要的块，而它们本身是不需要这些块的。 因此， BitSwap的节点很积极去给对端节点发送块，期待获得报酬。但必须防止水蛭攻击（空负载节点从不共享块），一个简单的类似信用的系统解决了这些问题：
1. 对等节点间会追踪他们的平衡（通过字节认证的方式）。
2. 随着债务增加而概率降低，对等者概率的向债务人发送块。&lt;/p&gt;

&lt;p&gt;如果节点决定不发送到对等节点，节点随后忽略对等体的ignore_cooldown超时。 这样可以防止发送者尝试多次发送（洪水攻击） （BitSwap默认是10秒）。&lt;/p&gt;

&lt;h4 id=&#34;3-4-2-bitswap策略&#34;&gt;3.4.2 BitSwap策略&lt;/h4&gt;

&lt;p&gt;BitSwap 对等节点采用很多不同的策略，这些策略对整个数据块的交换执行力产生了不同的巨大影响。在BitTorrent 中， 标准策略是特定的（tit-for-tat），从BitTyrant [8]（尽可能分享）到BitThief [8]（利用一个漏洞，从不共享），到PropShare [8]（按比例分享），其他不同的策略也已经被实施。BitSwap 对等节点可以类似地实现一系列的策略（良好和恶意）。对于功能的选择，应该明确：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为整个交易和节点最大化交易成绩。&lt;/li&gt;
&lt;li&gt;防止空负载节点利用和损害交易。&lt;/li&gt;
&lt;li&gt;高效抵制未知策略&lt;/li&gt;
&lt;li&gt;对可信任的对等节点更宽容。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;探索这些策略的空白是未来的事情。在实践中使用的一个选择性功能是sigmoid，根据负债比例进行缩放：
让负债比例在一个节点和它对等节点之间：
&lt;code&gt;r =  bytes_sent  / bytes_recv + 1&lt;/code&gt;根据r，发送到负债节点的概率为：&lt;code&gt;P(send | r ) = 1 − ( 1/  ( 1 + exp(6 − 3r) ) )&lt;/code&gt;
从图片1中看到，当节点负债比例超过节点已建立信贷的两倍，发送到负债节点的概率就会急速下降。
负债比是信任的衡量标准：对于之前成功的互换过很多数据的节点会宽容债务，而对不信任不了解的节点会严格很多。这个(a)给与那些创造很多节点的攻击者（sybill 攻击）一个障碍。(b)保护了之前成功交易节点之间的关系，即使这个节点暂时无法提供数据。&amp;copy;最终阻塞那些关系已经恶化的节点之间的通信，直到他们被再次证明。&lt;/p&gt;

&lt;h4 id=&#34;3-4-3-bitswap账本&#34;&gt;3.4.3 BitSwap账本&lt;/h4&gt;

&lt;p&gt;BitSwap节点保存了一个记录与所有其他节点之间交易的账本。这个可以让节点追踪历史记录以及避免被篡改。当激活了一个链接，BitSwap节点就会互换它们账本信息。如果这些账本信息并不完全相同，分类账本将会重新初始化， 那些应计信贷和债务会丢失。 恶意节点会有意去失去“这些“账本， 从而期望清除自己的债务。节点是不太可能在失去了应计信托的情况下还能累积足够的债务去授权认证。伙伴节点可以自由的将其视为不当行为， 拒绝交易。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Ledger struct {
    owner NodeId
    partner NodeId
    bytes_sent int
    bytes_recv int
    timestamp Timestamp
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;节点可以自由的保留分布式账本历史，这不需要正确的操作，因为只有当前的分类账本条目是有用的。节点也可以根据需要自由收集分布式帐本，从不太有用的分布式帐开始：老（其他对等节点可能不存在）和小。&lt;/p&gt;

&lt;h4 id=&#34;3-4-4-bitswap设计详述&#34;&gt;3.4.4 BitSwap设计详述&lt;/h4&gt;

&lt;p&gt;BitSwap 节点有以下简单的协议。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Additional state kept
type BitSwap struct {
    ledgers map[NodeId]Ledger
    // Ledgers known to this node, inc inactive
    active map[NodeId]Peer
    // currently open connections to other nodes
    need_list []Multihash
    // checksums of blocks this node needs
    have_list []Multihash
    // checksums of blocks this node has
}
type Peer struct {
    nodeid NodeId
    ledger Ledger
    // Ledger between the node and this peer
    last_seen Timestamp
    // timestamp of last received message
    want_list []Multihash
    // checksums of all blocks wanted by peer
    // includes blocks wanted by peer’s peers
}
// Protocol interface:
interface Peer {
    open (nodeid :NodeId, ledger :Ledger);
    send_want_list (want_list :WantList);
    send_block (block :Block) -&amp;gt; (complete :Bool);
    close (final :Bool);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对等连接的生命周期草图：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open: 对等节点间发送ledgers 直到他们同意。&lt;/li&gt;
&lt;li&gt;Sending: 对等节点间交换want_lists 和blocks。&lt;/li&gt;
&lt;li&gt;Close: 对等节点断开链接。&lt;/li&gt;
&lt;li&gt;Ignored: （特殊）对等被忽略（等待时间的超时）如果节点采用防止发送策略。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Peer.open(NodeId, Ledger).&lt;/p&gt;

&lt;p&gt;当发生链接的时候，节点会初始化链接的账本，要么保存一个份链接过去的账本，要么创建一个新的被清零的账本。然后，发送一个携带账本的open信息给对等节点。
接收到一个open信息之后，对等节点可以选择是否接受此链接。如果，根据接收者的账本，发送者是一个不可信的代理（传输低于零或者有很大的未偿还的债务），接收者可能会选择忽略这个请求。忽略请求是ignore_cooldown超时来概率性实现的，为了让错误能够有时间改正和攻击者被挫败。
如果链接成功，接收者用本地账本来初始化一个Peer对象以及设置last_seen时间戳。然后，它会将接受到的账本与自己的账本进行比较。如果两个账本完全一样，那么这个链接就被Open，如果账本并不完全一致，那么此节点会创建一个新的被清零的账本并且会发送此账本。&lt;/p&gt;

&lt;p&gt;Peer.send_want_list(WantList)&lt;/p&gt;

&lt;p&gt;当链接已经Open的时候，节点会广发它们的want_list给所有已经链接的对等节点。这个是在(a)open链接后(b)随机间歇超时后&amp;copy;want_list改变后(d)接收到一个新的块之后完成的。
当接收到一个want_list之后，节点会存储它。然后，会检查自己是否拥有任何它想要的块。如果有，会根据上面提到的BitSwap策略来将want_list所需要的块发送出去。&lt;/p&gt;

&lt;p&gt;Peer.send_block(Block)&lt;/p&gt;

&lt;p&gt;发送一个块是直接了当的。节点只是传输数据块。当接收到了所有数据的时候，接收者会计算多重hash校验和来验证它是否是自己所需数据，然后发送确认信息。
在完成一个正确的块传输之后，接受者会将此块从need_list一到have_list,最后接收者和发送者都会更新它们的账本来反映出传输的额外数据字节数。
如果一个传输验证失败了，发送者要么会出故障要么会攻击接收者，接收者可以选择拒绝后面的交易。注意，BitSwap是期望能够在一个可靠的传输通道上进行操作的，所以传输错误（可能会引起一个对诚实发送者错误的惩罚）是期望在数据发送给BitSwap之前能够被捕捉到。&lt;/p&gt;

&lt;p&gt;Peer.close(Bool)&lt;/p&gt;

&lt;p&gt;传给close最后的一个参数，代表close链接是否是发送者的意愿。如果参数值为false,接收者可能会立即重新open链接，这避免链过早的close链接。
一个对等节点close链接发生在下面两种情况下：
silence_wait超时已经过期，并且没有接收到来自于对等节点的任何信息（BitSwap默认使用30秒），节点会发送Peer.close(false)。
在节点退出和BitSwap关闭的时候，节点会发送Peer.close(true).
接收到close消息之后，接收者和发送者会断开链接，清除所有被存储的状态。账本可能会被保存下来为了以后的便利，当然，只有在被认为账本以后会有用时才会被保存下来。&lt;/p&gt;

&lt;p&gt;注意:
非open信息在一个不活跃的连接上应该是被忽略的。在发送send_block信息时，接收者应该检查这个块，看它是否是自己所需的，并且是否是正确的，如果是，就使用此块。总之，所有不规则的信息都会让接收者触发一个close(false)信息并且强制性的重初始化此链接。&lt;/p&gt;

&lt;h3 id=&#34;3-5-merkle-dag对象&#34;&gt;3.5 Merkle DAG对象&lt;/h3&gt;

&lt;p&gt;DHT和BitSwap允许IPFS形成一个大规模的对等网络系统来快速并且健壮的存储和发布块文件。在这些之上, IPFS构建了一个Merkle DAG: 一个有向无环图，其中对象之间的链接是嵌入在源中的目标的加密散列。这是Git数据结构的泛化应用。MerKle DAGs为IFPS提供了许多有用的特性，包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;内容寻址: 所有的内容都通过它的multihash校验和唯一标识，包括links。&lt;/li&gt;
&lt;li&gt;防止篡改: 所有的内容通过它的校验和验证。如果数据被篡改或者损坏，IPFS会探测出。&lt;/li&gt;
&lt;li&gt;重复删除: 所有的对象内容完全相同便会只存储一份。对于索引对象尤其有用。例如git的tree和commit对象，以及数据的共同部分。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;IFPS对象的格式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type IPFSLink struct {
    Name string
    // name or alias of this link
    Hash Multihash
    // cryptographic hash of target
    Size int
    // total size of target
}
type IPFSObject struct {
    links []IPFSLink
    // array of links
    data []byte
    // opaque content data
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IPFS的Merkle DAG是存储数据的一种非常灵活的方式。唯一的要求是对象的引用是(a)内容可寻址, (b)以之前描述的格式编码。IPFS给予应用对于data字段的完全控制权。应用可以定制任何数据格式，即使IPFS不能够理解。独立的内部对象link表允许IPFS:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;列出一个对象列表中所有的对象引用，比如:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; ipfs ls /XLZ1625Jjn7SubMDgEyeaynFuR84ginqvzb
XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x 189458 less  
XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5 19441 script
XLF4hwVHsVuZ78FZK6fozf8Jj9WEURMbCX4 5286 template
&amp;lt;object multihash&amp;gt; &amp;lt;object size&amp;gt; &amp;lt;link name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;解决字符串路径查询，比如&lt;code&gt;foo/bar/baz&lt;/code&gt;。给定一个对象,IPFS将第一个路径部分映射成对象link表里面的一个hash，获取第二部分对象。然后重复至下一个路径部分。因此任何数据格式的字符串路径都可以通过Merkle DAG定位位置。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;解析递归引用的所有对象:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; ipfs refs --recursive \
/XLZ1625Jjn7SubMDgEyeaynFuR84ginqvzb
XLLxhdgJcXzLbtsLRL1twCHA2NrURp4H38s
XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x
XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5
XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个原始data字段和通用link结构是构建IPFS顶层中的任意数据结构的必要组件。
通过观察如下数据结构: (a) 键值对存储, (b)传统关系型数据, &amp;copy;关联数据三层存储, (d) 关联文档发布系统, (e)通信平台, (f)加密货币区块, 可以容易的得知Git的对象模型是如何使用DAG。这些都可以通过IPFS的Merkle DAG建模，使得一些更复杂的系统使用IPFS系统作为传输层协议。&lt;/p&gt;

&lt;h4 id=&#34;3-5-1路径&#34;&gt;3.5.1路径&lt;/h4&gt;

&lt;p&gt;通过字符串路径API可以遍历IPFS对象。路径的工作方式与传统的UNIX文件系统和Web一致。Merkle DAG links使得访问很容易。IPFS完整路径格式如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# format
/ipfs/&amp;lt;hash-of-object&amp;gt;/&amp;lt;name-path-to-object&amp;gt;
# example
/ipfs/XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x/foo.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;/ipfs前缀允许挂载到现在系统中的一个无冲的标准挂载点上(挂载点的名称是可以配置的)。路径第二个部分是对象的hash。通常情况下，没有一个全局跟路径。一个根对象需要来处理分布式系统中的百万个对象的一致性，这是一个不可能的任务。因此，我们模拟通过内容地址来模拟根地址。所有的对象总是可以通过他们的hash访问到。意味着给定地址&lt;code&gt;&amp;lt;foo&amp;gt;/bar/baz&lt;/code&gt;的三个对象, 最后一个对象可以通过以下方式获取:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/ipfs/&amp;lt;hash-of-foo&amp;gt;/bar/baz
/ipfs/&amp;lt;hash-of-bar&amp;gt;/baz
/ipfs/&amp;lt;hash-of-baz&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-5-2本地对象&#34;&gt;3.5.2本地对象&lt;/h4&gt;

&lt;p&gt;IPFS客户端需要local storage, 一个外部系统用来存储并且检索本地原生数据，以便管理IPFS对象。存数的类型取决于节点的使用方式。大多数情况下，仅仅是硬盘空间的分配(或者通过文件系统管理，或者通过类似leveldb的键值存储，或者直接通过IPFS客户端)。其他情况下，比如非持久的缓存场景中，存储需要RAM的分配。&lt;br /&gt;
IPFS中所有的块都在节点的local storage。当用户获取对象时，对象被查到到然后下载最后存储在本地，至少是临时存储。这为一些可配置时间量提供了快速查询。&lt;/p&gt;

&lt;h4 id=&#34;3-5-3对象固定&#34;&gt;3.5.3对象固定&lt;/h4&gt;

&lt;p&gt;节点可以通过固定对象的方式来确保特定对象的生存。这样确保了此对象存储在节点的local storage中。固定操作可以使递归的，继而将所有关联的后代对象固定。所有的对象都在本地存储。在持久化文件中很有用处，包括引用。同样使得IPFS成为一个连接是永久的Web，并且对象可以确保其他被指定对象的生存。&lt;/p&gt;

&lt;h4 id=&#34;3-5-4对象发布&#34;&gt;3.5.4对象发布&lt;/h4&gt;

&lt;p&gt;IPFS是全球分发的。它被设计为允许用户成千上万的文件共同存在。通过内容哈希寻址，DHT可以在一种公平安全, 完全分布式的方式发布对象。任何人都可以通过简单的向DHT中添加对象的键来发布对象, 并且以对象是对等的方式添加, 别人通过这个对象的路径来访问。对象本质上是不可改变的, 就像Git。新的版本的hash是不同的, 意味着是新的对象。跟踪版本是额外版本对象的一个工作。&lt;/p&gt;

&lt;h4 id=&#34;3-5-5对象级别加密&#34;&gt;3.5.5对象级别加密&lt;/h4&gt;

&lt;p&gt;IPFS拥有处理对象级别加密的操作，一个加密或者签名的对象是被包裹在一个特殊的frame中，这个frame允许加密或者验证原生数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type EncryptedObject struct {
    Object []bytes
    // raw object data encrypted
    Tag []bytes
    // optional tag for encryption groups
}
type SignedObject struct {
    Object []bytes
    // raw object data signed
    Signature []bytes
    // hmac signature
    PublicKey []multihash
    // multihash identifying key
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;加密操作改变了对象的hash，被定义为一个新的对象。IPFS自动验证签名并且通过用户声明钥匙链解密数据。加密数据的links同样也被保护, 没有解密钥匙便不能遍历。父对象和子对象使用不同的加密密钥是可行。这种方式保证分享对象links的安全。&lt;/p&gt;

&lt;h3 id=&#34;3-6-文件&#34;&gt;3.6 文件&lt;/h3&gt;

&lt;p&gt;IPFS同样定义了一系列的对象来为Merkle DAG顶层的版本文件系统建立模型。对象模型类似于Git:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;block: 可变的数据块&lt;/li&gt;
&lt;li&gt;list: 一个blocks或者别的list的集合&lt;/li&gt;
&lt;li&gt;tree: 一个blocks或者lists或者别的tree的集合&lt;/li&gt;
&lt;li&gt;commit: 版本历史中一个tree的快照&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我希望完全使用Git对象格式，但就需要分开来引入分布式系统中有用的特性。他们是, (a) 快速大小查询(总子节已经被添加到对象中), (b) 大文件去重(添加一个list对象), &amp;copy;将嵌入commits到trees中。总之，IPFS文件对象很接近Git，两者有可能进行交流。而且，一些Git对象可以在没有丢失信息(比如UNIX文件权限等)的情况下转换被引入。
注意: 文件对象使用JSON格式。虽然ipfs包括了JSON的导入导出，实际上这些结构是使用protobufs的二进制编码。&lt;/p&gt;

&lt;h4 id=&#34;3-6-1文件对象-blob&#34;&gt;3.6.1文件对象: blob&lt;/h4&gt;

&lt;p&gt;blob对象包含了一个可寻址的数据单元, 并且标识一个文件。IPFS Blocks类似Git的blobs或者文件系统的数据块。他们存储着用户的数据。注意, IPFS文件可以使用lists或者blobs来表示。blobs没有links。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&amp;quot;data&amp;quot;: &amp;quot;some data here&amp;quot;,
// blobs have no links
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-6-2文件对象-list&#34;&gt;3.6.2文件对象: list&lt;/h4&gt;

&lt;p&gt;list对象是一个通过一些IPFS blobs聚合一起形成的大的或者去重的文件的表示。lists包含一个关于blob或者list的顺序序列。IPFS list的作用类似文件系统中的间接blocks。由于lists可以包含其他的lists, 拓扑包含带链接的lists和平衡数是有可能的。有向图中相同的节点在不同的位置使得文件内部去重。由于强制哈希寻址，环是不可能的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&amp;quot;data&amp;quot;: [&amp;quot;blob&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;blob&amp;quot;],
    // lists have an array of object types as data
&amp;quot;links&amp;quot;: [
    { &amp;quot;hash&amp;quot;: &amp;quot;XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x&amp;quot;,&amp;quot;size&amp;quot;: 189458 },
    { &amp;quot;hash&amp;quot;: &amp;quot;XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5&amp;quot;, &amp;quot;size&amp;quot;: 19441 },
    { &amp;quot;hash&amp;quot;: &amp;quot;XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z&amp;quot;, &amp;quot;size&amp;quot;: 5286 }
    // lists have no names in links
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-6-3文件对象-tree&#34;&gt;3.6.3文件对象: tree&lt;/h4&gt;

&lt;p&gt;IPFS中的tree对象类似Git中的。表示一个目录, 一个名称和哈希的映射。这些哈希表示着blobs, lists, 别的tree或者commits。注意传统的路径名称已经被Merkle DAG实现。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&amp;quot;data&amp;quot;: [&amp;quot;blob&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;blob&amp;quot;],
    // trees have an array of object types as data
&amp;quot;links&amp;quot;: [
  { &amp;quot;hash&amp;quot;: &amp;quot;XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;less&amp;quot;, &amp;quot;size&amp;quot;: 189458 },
  { &amp;quot;hash&amp;quot;: &amp;quot;XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;script&amp;quot;, &amp;quot;size&amp;quot;: 19441 },
  { &amp;quot;hash&amp;quot;: &amp;quot;XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;template&amp;quot;, &amp;quot;size&amp;quot;: 5286 }
    // trees do have names
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-6-4文件对象-commit&#34;&gt;3.6.4文件对象: commit&lt;/h4&gt;

&lt;p&gt;commit对象表示着一个对象在版本历史中的一个快照。和Git中的类似，不过可以引用任何类型。可以链接作者的对象。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&amp;quot;data&amp;quot;: {
    &amp;quot;type&amp;quot;: &amp;quot;tree&amp;quot;,
    &amp;quot;date&amp;quot;: &amp;quot;2014-09-20 12:44:06Z&amp;quot;,
    &amp;quot;message&amp;quot;: &amp;quot;This is a commit message.&amp;quot;
},
&amp;quot;links&amp;quot;: [
    { &amp;quot;hash&amp;quot;: &amp;quot;XLa1qMBKiSEEDhojb9FFZ4tEvLf7FEQdhdU&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;parent&amp;quot;, &amp;quot;size&amp;quot;: 25309 },
    { &amp;quot;hash&amp;quot;: &amp;quot;XLGw74KAy9junbh28x7ccWov9inu1Vo7pnX&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;object&amp;quot;, &amp;quot;size&amp;quot;: 5198 },
    { &amp;quot;hash&amp;quot;: &amp;quot;XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;author&amp;quot;, &amp;quot;size&amp;quot;: 109 }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-6-5版本控制&#34;&gt;3.6.5版本控制&lt;/h4&gt;

&lt;h4 id=&#34;3-6-6文件系统路径&#34;&gt;3.6.6文件系统路径&lt;/h4&gt;

&lt;p&gt;通过Merkle DAG小节, IPFS对象通过字符串路径API遍历。IPFS文件对象被设计成更容易挂载到UNIX文件系统上。为了表示trees为目录，他们限制trees没有数据。并且commit可以被表示成目录或者完全隐藏在文件系统。&lt;/p&gt;

&lt;h4 id=&#34;3-6-7文件分割成lists和blob&#34;&gt;3.6.7文件分割成Lists和Blob&lt;/h4&gt;

&lt;p&gt;对于大文件的版本和分布式化的一个主要挑战就是找到合理的方式来切分它成blocks。与其假设不同类型的文件有正确的切分法，不如说IPFS提供了如下选择:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(a) 使用LBFS[?]中的Rabin Fingerprints[?]方法来选择合适的block边界。&lt;/li&gt;
&lt;li&gt;(b) 使用rsync[?] rolling-checksum算法, 来检测版本之间的块变动。&lt;/li&gt;
&lt;li&gt;&amp;copy; 允许用户为制定的文件来设定块分割算法&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-6-8路径查询性能&#34;&gt;3.6.8路径查询性能&lt;/h4&gt;

&lt;p&gt;基于路径访问需要遍历对象图。检索每一个对象需要查询DHT中对应的密钥, 连接到对应的对等节点, 检索出它的blocks。这是很大的开销，尤其是在查询路径中存在许多子路径构成。通过以下方式来缓和:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tree caching: 由于所有的对象都是哈希可寻址的, 他们可以被无限的缓存。此外, trees的大小更小一些，IPFS更倾向在blobs之上缓存它们。&lt;/li&gt;
&lt;li&gt;flattened trees: 对于给定的tree, 一个特殊的flattened tree可以被构建成一个链表, 所有对象从这个tree中访问得到。flattened tree中的名称可以分别通过原始tree以分隔符连接获得。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;例如, ttt111的flattened tree如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&amp;quot;data&amp;quot;:
    [&amp;quot;tree&amp;quot;, &amp;quot;blob&amp;quot;, &amp;quot;tree&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;blob&amp;quot; &amp;quot;blob&amp;quot;],
&amp;quot;links&amp;quot;: [
    { &amp;quot;hash&amp;quot;: &amp;quot;&amp;lt;ttt222-hash&amp;gt;&amp;quot;, &amp;quot;size&amp;quot;: 1234
    &amp;quot;name&amp;quot;: &amp;quot;ttt222-name&amp;quot; },
    { &amp;quot;hash&amp;quot;: &amp;quot;&amp;lt;bbb111-hash&amp;gt;&amp;quot;, &amp;quot;size&amp;quot;: 123,
    &amp;quot;name&amp;quot;: &amp;quot;ttt222-name/bbb111-name&amp;quot; },
    { &amp;quot;hash&amp;quot;: &amp;quot;&amp;lt;ttt333-hash&amp;gt;&amp;quot;, &amp;quot;size&amp;quot;: 3456,
    &amp;quot;name&amp;quot;: &amp;quot;ttt333-name&amp;quot; },
    { &amp;quot;hash&amp;quot;: &amp;quot;&amp;lt;lll111-hash&amp;gt;&amp;quot;, &amp;quot;size&amp;quot;: 587,
    &amp;quot;name&amp;quot;: &amp;quot;ttt333-name/lll111-name&amp;quot;},
    { &amp;quot;hash&amp;quot;: &amp;quot;&amp;lt;bbb222-hash&amp;gt;&amp;quot;, &amp;quot;size&amp;quot;: 22,
    &amp;quot;name&amp;quot;: &amp;quot;ttt333-name/lll111-name/bbb222-name&amp;quot; },
    { &amp;quot;hash&amp;quot;: &amp;quot;&amp;lt;bbb222-hash&amp;gt;&amp;quot;, &amp;quot;size&amp;quot;: 22
    &amp;quot;name&amp;quot;: &amp;quot;bbb222-name&amp;quot; }
] }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-7-ipns-命名空间和可变状态&#34;&gt;3.7 IPNS: 命名空间和可变状态&lt;/h3&gt;

&lt;p&gt;目前为止, IPFS协议栈通过构建一个内容可寻址的DAG对象集形成了一个点对点块交换系统。它用来发布和检索不可变对象。它可以追踪这些对象的版本变化。然而, 一个重要的部分缺失了: 可变的命名。没有此部分, 所有以IPFS links通信的新内容都会有所偏差。我们需要在一个相同的路径下检索可变的状态。
如果可变的数据到最后是必须的, 我们必须明确为什么我们努力构建了一套不可变的Merkle DAG。考虑到IPFS的特性: 对象可以(a)通过哈希检索 (b)完整性检查 &amp;copy;关联到其他对象 (d)无限的缓存。某种意义上:&lt;br /&gt;
&lt;strong&gt;对象是永久的&lt;/strong&gt;&lt;br /&gt;
这个也是高性能分布式系统的重要特性, 数据通过网络links来移动是昂贵的。对象内容可寻址构建了一个具有以下特点的web:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(a) 显著的带宽优化&lt;/li&gt;
&lt;li&gt;(b) 非信任的内容服务&lt;/li&gt;
&lt;li&gt;&amp;copy; 永久的链接&lt;/li&gt;
&lt;li&gt;(d) 任何一个对象和它的引用的完整永久性备份&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于不可变的内容可寻址的对象和命名的Merkle DAG和指向Merkle DAG的可变的指针, 实例化了一个呈现在许多成功的分布式系统中的二分法。他们包括Git版本控制系统, 拥有不可变的对象和可变的引用。Plan9[?]拥有可变的Fossil[?]和不可变的Venti[?]文件系统。LBFS[?]同样拥有可变的indices和不可变的chunks。&lt;/p&gt;

&lt;h4 id=&#34;3-7-1自我认证命名&#34;&gt;3.7.1自我认证命名&lt;/h4&gt;

&lt;p&gt;通过SFS[12, 11]的命名方案，我们得到一个方式，在整个加密制定的命名空间中构建自我认证的命名，并且是可变的。IPFS的方案如下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;回想IPFS中: NodeId = hash(node.PubKey)&lt;/li&gt;
&lt;li&gt;我们给每一个用户分配了一个可变的命名空间: &lt;code&gt;/ipns/&amp;lt;NodeId&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;一个用户可以通过附上它的私钥签名发布一个对象到这个路径上, 比如:&lt;code&gt;/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;当别的用户检索这个对象时, 他们可以检查这个签名是否匹配公钥和NodeId。这将验证用户发布对象的真实性，获取可变状态的查询。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意细节:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ipns(InterPlanetary Name Space)独立的前缀是为了建立一个简单的识别区分来区分可变和不可变的路径, 为了程序也为了人们阅读。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;由于这不是一个内容可寻址的对象，发布它需要依赖IPFS可变状态分发系统, 路由系统。过程是(1)按照常规不可变IPFS对象发布对象, (2) 在路由系统中发布它的哈希作为一个meta元数据值:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;routing.setValue(NodeId, &amp;lt;ns-object-hash&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;被发布的对象的任何links被视为命名空间的子名称:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/
/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/docs
/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/docs/ipfs
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;被推荐发布一个commit对象, 或者版本历史系统的别的对象, 以至于客户端可以找到旧的名称。这样便留给用户一个选择。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注意当用户发布这个对象时, 它不能用相同的方式发布。&lt;/p&gt;

&lt;h4 id=&#34;3-7-2人类可读命名&#34;&gt;3.7.2人类可读命名&lt;/h4&gt;

&lt;p&gt;IPNS确实是一种方式来分发和再分发命名, 不过它还是暴露的长长的hash值作为命名, 对于用户不是很友好,很难记忆。IPFS通过一下技术增强用户友好的IPNS。&lt;/p&gt;

&lt;h5 id=&#34;peer-links&#34;&gt;Peer Links&lt;/h5&gt;

&lt;p&gt;收到SFS的启发, 用户可以直接关联别人的对象到自己的对象中(命名空间,home)。这样同样增加了网络信任。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Alice links to bob Bob
ipfs link /&amp;lt;alice-pk-hash&amp;gt;/friends/bob /&amp;lt;bob-pk-hash&amp;gt;
# Eve links to Alice
ipfs link /&amp;lt;eve-pk-hash/friends/alice /&amp;lt;alice-pk-hash&amp;gt;
# Eve also has access to Bob
/&amp;lt;eve-pk-hash/friends/alice/friends/bob
# access Verisign certified domains
/&amp;lt;verisign-pk-hash&amp;gt;/foo.com
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;dns-txt-ipns-记录&#34;&gt;DNS TXT IPNS 记录&lt;/h5&gt;

&lt;p&gt;如果/ipns/&amp;lt;domain&amp;gt;是一个有效的域名名称, IPFS可以在自己的DNS TXT记录中查找ipns键。IPFS翻译那个值或者作为一个对象hash或者另一个IPNS路径:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# this DNS TXT record
ipfs.benet.ai. TXT &amp;quot;ipfs=XLF2ipQ4jD3U ...&amp;quot;
# behaves as symlink
ln -s /ipns/XLF2ipQ4jD3U /ipns/fs.benet.ai
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;proquint-pronounceable-identifiers&#34;&gt;Proquint Pronounceable Identifiers&lt;/h5&gt;

&lt;p&gt;有方案将二进制转换成可发音的单词。IPNS支持Proquint[?]。如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# this proquint phrase
/ipns/dahih-dolij-sozuk-vosah-luvar-fuluh
# will resolve to corresponding
/ipns/KhAwNprxYVxKqpDZ
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;name-shortening-services&#34;&gt;Name Shortening Services&lt;/h5&gt;

&lt;p&gt;涌现出提供缩短名称的服务, 向用户提供他们的命名空间。就像我们现在看到的DNS和Web的URLs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# User can get a link from
/ipns/shorten.er/foobar
# To her own namespace
/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-8-ipfs使用场景&#34;&gt;3.8 IPFS使用场景&lt;/h3&gt;

&lt;p&gt;IPFS设计为可以使用多种不同的方法来使用的，下面就是一些我将会继续追求的使用方式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;作为一个挂载的全局文件系统，挂载在/ipfs和/ipns下&lt;/li&gt;
&lt;li&gt;作为一个挂载的个人同步文件夹，自动的进行版本管理，发布，以及备份任何的写入&lt;/li&gt;
&lt;li&gt;作为一个加密的文件或者数据共享系统&lt;/li&gt;
&lt;li&gt;作为所有软件的版本包管理者&lt;/li&gt;
&lt;li&gt;作为虚拟机器的根文件系统&lt;/li&gt;
&lt;li&gt;作为VM的启动文件系统 (在管理程序下)&lt;/li&gt;
&lt;li&gt;作为一个数据库：应用可以直接将数据写入Merkle DAG数据模型中，获取所有的版本，缓冲，以及IPFS提供的分配&lt;/li&gt;
&lt;li&gt;作为一个linked（和加密的）通信平台&lt;/li&gt;
&lt;li&gt;作为一个为大文件的完整性检查CDN（不使用SSL的情况下）&lt;/li&gt;
&lt;li&gt;作为一个加密的CDN&lt;/li&gt;
&lt;li&gt;在网页上，作为一个web CDN&lt;/li&gt;
&lt;li&gt;作为一个links永远存在新的永恒的Web&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;IPFS实现的目标：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(a)一个IPFS库可以导出到你自己应用中使用&lt;/li&gt;
&lt;li&gt;(b)命令行工具可以直接操作对象&lt;/li&gt;
&lt;li&gt;&amp;copy;使用FUSE[?]或者内核的模型挂载文件系统&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-未来&#34;&gt;4. 未来&lt;/h2&gt;

&lt;h2 id=&#34;5-感谢&#34;&gt;5. 感谢&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>Bloomfilter算法实现</title>
      <link>https://wadevan.github.io/2017/bloomfilter%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 07 Aug 2017 19:49:41 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2017/bloomfilter%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</guid>
      
        <description>

&lt;h2 id=&#34;bloom-filter&#34;&gt;Bloom Filter&lt;/h2&gt;

&lt;p&gt;Bloom Filter是由Bloom在1970年提出的一种快速查找算法，通过多个hash算法来共同判断一个元素（字符串）是否在这个集合内，空间利用效率很高。Bloomfilter中保存了一个n位的bit数组， 当一个元素被加到这个集合时，这个元素的key通过k个hash算法生成k个值，然后将内存数组对应的k个位置置1。判断一个元素是否在集合中，只需要查看Bloomfilter的内存数组k个位置是否全为1。当其中一个不是1时，此元素不在集合中。bloomfilter判断一个元素属于当前集合时，存在一定的误差率e。&lt;/p&gt;

&lt;h2 id=&#34;误差率e&#34;&gt;误差率e&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html&#34;&gt;bloom filter-math&lt;/a&gt;详细的推倒了误差率e和集合元素n，bit数组m以及hash算法个数之间的关系。总结如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;e = (1 - ((1 - 1/ m) ^ kn))^k ~= (1 - e^(-kn/m))^k
k = (m / n) * ln2 //k最优解公式
m&amp;gt;=nlg(1/E)*lge // 当误差率e&amp;lt;E时，m和n的关系
...
e &amp;lt; 0.1: k = 3.321928, m/n = 4.79
e &amp;lt; 0.01: k = 6.643856, m/n = 9.58
e &amp;lt; 0.001: k = 9.965784, m/n = 14.37
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/slumber1122/bloomfilter&#34;&gt;Bloom Filter&lt;/a&gt;基于简单的加法Hash算法实现了一个Bloom Filter。通过给定误差率e和集合amount生成最优的Bloom filter。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>ipfs上部署静态网站</title>
      <link>https://wadevan.github.io/2017/ipfs%E4%B8%8A%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99/</link>
      <pubDate>Thu, 27 Jul 2017 19:36:56 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2017/ipfs%E4%B8%8A%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99/</guid>
      
        <description>

&lt;h2 id=&#34;ipfs&#34;&gt;IPFS&lt;/h2&gt;

&lt;p&gt;ipfs是一个内容可寻址的点对点超媒体协议。基于http协议的网络中，我们获取内容需要先连接上内容所在的服务器，然后获取内容。ipfs网络中，所有的文件通过&lt;a href=&#34;https://en.wikipedia.org/wiki/Cryptographic_hash_function&#34;&gt;加密哈希&lt;/a&gt;映射到一个空间中，并且能够保证唯一。
在获取一个内容时，我们知道这个内容对应的哈希key，通过&lt;a href=&#34;https://en.wikipedia.org/wiki/Distributed_hash_table&#34;&gt;DHT&lt;/a&gt;算法，可以在一个巨大的网络节点中快速找到拥有数据的节点(在一个拥有10,000,000个节点的网络中只需要20跳)，从而检索出数据。 除了上述技术之外，IPFS也融合了git的版本管理，BitTorrent的bitswap，Self-Certified Filesystems等技术。&lt;/p&gt;

&lt;h2 id=&#34;ipfs的基本操作&#34;&gt;IPFS的基本操作&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// ipfs 初始化
&amp;gt; ipfs init
initializing ipfs node at /Users/jbenet/.go-ipfs
generating 2048-bit RSA keypair...done
peer identity: Qmcpo2iLBikrdf1d6QU6vXuNb6P7hwrbNPW9kLAH8eG67z
to get started, enter:

  ipfs cat /ipfs/QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG/readme

// 启动deamon
&amp;gt; ipfs daemon
Initializing daemon...
API server listening on /ip4/127.0.0.1/tcp/5001
Gateway server listening on /ip4/127.0.0.1/tcp/8080

// 获取文件
ipfs cat /ipfs/QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ/cat.jpg &amp;gt;cat.jpg
open cat.jpg

//上传文件
&amp;gt; hash=`echo &amp;quot;I &amp;lt;3 IPFS -$(whoami)&amp;quot; | ipfs add -q`
&amp;gt; curl &amp;quot;https://ipfs.io/ipfs/$hash&amp;quot;
I &amp;lt;3 IPFS -&amp;lt;your username&amp;gt;


//使用自己的gateway访问ipfs的资源
&amp;gt; curl &amp;quot;http://127.0.0.1:8080/ipfs/$hash&amp;quot;
I &amp;lt;3 IPFS -&amp;lt;your username&amp;gt;

//web console
http://localhost:5001/webui

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;添加website至ipfs&#34;&gt;添加website至IPFS&lt;/h2&gt;

&lt;p&gt;将静态网站部署至IPFS上非常简单&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  git:(master) ✗ ipfs add -r website
added QmV94V8W4bu1UUbNtVwafji7acSQyG8uPx1Tf6mRbLK9zo website/css/custom.css
added QmQAPL7vsWyQSMcMzKBzALWXzFDQSRuwcRpdTXs6oi2yyZ website/css/normalize.css
added QmRyrbwkktbe4SM4Q6ZYV1TENEwMKVfHBShnVbqyyKmovh website/css/skeleton.css
added QmXA57jefG32EnVMH9o69ubcKmGd6eH2YECa2w32KuBQtD website/images/me.jpg
added QmP283YcqfZ24e4db4ACFRwvKGqymTZ2o21dmJwok1Spdi website/index.html
added Qmd1KnoAM1yDTtHDEL9ghex2sbEGVgsSeQKcNhG1a6844z website/index.xml
added QmRw359MwfVryZGRZ1fWQbyNXyCwsHA26tiM9Jd9t6sco3 website/livereload.js?port=1313&amp;amp;mindelay=10
added QmZG3urHo2oJZ2wV1svrBXi18VsmkPyketqo8EYvHaQ7aj website/posts/blog_on_ipfs/index.html
added QmWTEZJZdGykuRxnoqNwLSu6zJ6WqbzNaDeJLX5ex97qF1 website/css
added QmbFctMzEuWoNKhXFjGbrbXNTM9hDXNM8JRxmj7Zspc7Bh website/images
added QmeBUwj2rmzhnGADd84wZ77p6GoHVsnrTaKEfavEerSjG1 website/posts/blog_on_ipfs
added QmcjgdnQe7uuriYBXCV6Lfdu3sDo3ASzWAdzBF1UTbtDHd website/posts
added QmZ86JMLnTpUnFx2Dg4iKQSXvQu7rkH4zWbfhEwQxGnVu5 website

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行之后就完成了部署。我们可以通过&lt;a href=&#34;https://ipfs.io/ipfs/QmZ86JMLnTpUnFx2Dg4iKQSXvQu7rkH4zWbfhEwQxGnVu5&#34;&gt;QmZ86JMLnTpUnFx2Dg4iKQSXvQu7rkH4zWbfhEwQxGnVu5&lt;/a&gt;来访问我们刚刚部署的website。&lt;br /&gt;
这里有一个前提，href中的路径都是基于website_dir的相对路径。如果你的website里面的路径是绝对路径，可以通过一些工具convert一下，&lt;code&gt;wget --mirror --convert-links --page-requisites http://you_site&lt;/code&gt;是一种简单的转化方式。&lt;br /&gt;
上述方法有个问题，由于ipfs的hash对应着一个不可变的内容，每次更新网站之后，website的hash都会变。旧的link不能访问到新的内容。&lt;br /&gt;
ipfs提供了ipns来解决更新的问题。ipfs允许用户使用一个私有密钥来对IPFS哈希附加一个引用，使用一个公共密钥哈希（简称pubkeyhash）表示你的网站的最新版本。具体操作是:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;update website content
➜  git:(master) ✗ sitehash=QmZ86JMLnTpUnFx2Dg4iKQSXvQu7rkH4zWbfhEwQxGnVu5
➜  git:(master) ✗ ipfs name publish $sitehash
...
update websit content
➜  git:(master) ✗ sitehash=QmRGfsCrkHHUFwZWKeV1DnL83FoJ5G4qTUnmhAR4HnfWtV
➜  git:(master) ✗ ipfs name publish $sitehash

Published to QmRpHvp6pH1gTMTvgngx5EWGEU3kFfP8VyDHkmg85KBkiu: /ipfs/QmRGfsCrkHHUFwZWKeV1DnL83FoJ5G4qTUnmhAR4HnfWtV
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过上述方式，就完成了website和一个固定的link的绑定，&lt;a href=&#34;https://ipfs.io/ipns/QmRpHvp6pH1gTMTvgngx5EWGEU3kFfP8VyDHkmg85KBkiu/&#34;&gt;QmRpHvp6pH1gTMTvgngx5EWGEU3kFfP8VyDHkmg85KBkiu&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果你有自己的domain，可用通过更新你的dns provider的配置，使得你的domain link到基于ipfs部署的website。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DNS TXT record
dnslink=/ipns/QmRpHvp6pH1gTMTvgngx5EWGEU3kFfP8VyDHkmg85KBkiu
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>使用nodejs部署智能合约</title>
      <link>https://wadevan.github.io/2017/%E4%BD%BF%E7%94%A8nodejs%E9%83%A8%E7%BD%B2%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/</link>
      <pubDate>Tue, 18 Jul 2017 19:44:56 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2017/%E4%BD%BF%E7%94%A8nodejs%E9%83%A8%E7%BD%B2%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/</guid>
      
        <description>

&lt;h2 id=&#34;使用nodejs部署智能合约&#34;&gt;使用nodejs部署智能合约&lt;/h2&gt;

&lt;p&gt;实现智能合约的方式很多种，可以用truffle框架来实现，编译，部署。
这里介绍一种简单的使用nodejs来实现，编译，部署的方法。
创建一个nodejs项目，实现一个简单的智能合约。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir sm &amp;amp;&amp;amp; cd sm
npm init
mkdir contracts &amp;amp;&amp;amp; cd contracts
vi BaseToken.sol

//BaseToken.sol
contract Token{
    address public owner;
    mapping (address =&amp;gt; uint) public balances;
    event Sent(address from, address to, uint amount)
    function Token(){
        owner = msg.sender;
        balances[owner] = 100000000;
    }
    function send(address receiver, uint amount){
        if (balances[msg.sender] &amp;lt; amount) return;
        balances[msg.sender] -= amount;
        balances[receiver] += amount;
        Sent(msg.sender, receiver, amount);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个合约实现了一个造币和转币的逻辑。
我们的合约是运行在evm上面的字节码，solidity是静态语言，需要通过编译器生成evm的字节码。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
vi compile.js

// compile.js
const fs = require(&#39;fs&#39;)
const solc = require(&#39;solc&#39;)
//编译合约
let source = fs.readFileSync(&amp;quot;./contracts/BaseToken.sol&amp;quot;, &#39;utf8&#39;)
console.log(&#39;compiling contract...&#39;);
let compiledContract = solc.compile(source);
console.log(&#39;done&#39;);

for (let contractName in compiledContract.contracts) {
    var bytecode = compiledContract.contracts[contractName].bytecode;
    var abi = JSON.parse(compiledContract.contracts[contractName].interface);
}
console.log(bytecode)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用&lt;code&gt;node compile.js&lt;/code&gt;,对BaseToken进行编译，生成字节码。web3中提供了一个部署合约的接口，使用如下，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let gasEstimate = web3.eth.estimateGas({data: &#39;0x&#39; + bytecode});
console.log(&#39;gasEstimate: &#39; + gasEstimate)


let MyContract = web3.eth.contract(abi);

console.log(&#39;deploying contract...&#39;);


let myContractReturned = MyContract.new([], {
  from: address,
  data: &#39;0x&#39; + bytecode,
  gas: gasEstimate+50000
}, function(err, myContract){
  if(!err){
    if(!myContract.address){
      console.log(`myContract.transactionHash = ${myContract.transactionHash}`);
    }else{
      console.log(`myContract.address = ${myContract.address}`); // the contract address
      global.contractAddress = myContract.address;
    }
}else{
    console.log(err);
}
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;利用编译生成的abi和bytecode，创建一个合约对象，然后进行发布，等待着异步执行的方法输出合约地址&lt;code&gt;contractAddress&lt;/code&gt;，这样就完成了部署。不过这种方式有一个问题，就是在发布合约时，你的私钥处于联网状态，
处于安全策略，我们需要尽量避免私钥在联网状态。&lt;/p&gt;

&lt;p&gt;以太坊上部署合约是向空地址发送一个附有字节码的签名交易，其中发送者就是这个合约的拥有者。因此我们只需要将合约构建成一笔交易，我们在无网状态下对这笔交易进行签名，然后将签名发送到以太坊网络中。这样能够降低我们私钥被泄漏的风险。
对合约的签名方法如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var Tx = require(&#39;ethereumjs-tx&#39;)
const rawTx = {
    nonce: &#39;0x6&#39;, //这个是你的地址的交易次数+1，0开始
    gasPrice: &#39;0x12a05f200&#39;,
    gasLimit: &#39;0x493e0&#39;,
    data: bytecode,
    from: address,
    to: &amp;quot;&amp;quot;
};
const tx = new Tx(rawTx);
tx.sign(privateKey);
const serializedTx = tx.serialize();
console.log(serializedTx.toString(&#39;hex&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上对一个合约签名，这里需要注意的问题是，to的地址需要是，空地址。
完成签名之后，我们把这笔交易发送出去就好，最简单的方法就是使用&lt;a href=&#34;https://etherscan.io/pushTx&#34;&gt;etherscan的发送Tx的方式&lt;/a&gt;，一旦发送完成，部署完成，就可以看到合约地址。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Hugo搭建Github Pages静态网站</title>
      <link>https://wadevan.github.io/2016/hugo%E6%90%AD%E5%BB%BAgithub-pages%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99/</link>
      <pubDate>Sat, 29 Oct 2016 12:17:00 +0800</pubDate>
      
      <guid>https://wadevan.github.io/2016/hugo%E6%90%AD%E5%BB%BAgithub-pages%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99/</guid>
      
        <description>

&lt;h3 id=&#34;安装hugo创建初始网站&#34;&gt;安装Hugo创建初始网站&lt;/h3&gt;

&lt;p&gt;安装hugo&lt;code&gt;$ brew update &amp;amp;&amp;amp; brew install hugo&lt;/code&gt;&lt;br /&gt;
创建自己的站点&lt;code&gt;$ hugo new site mysite&lt;/code&gt;&lt;br /&gt;
会生成以下目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;content/
static/
themes/
config.toml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;config.toml是网站的配置文件，一个TOML文件，全称是Tom’s Obvious, Minimal Language，这是它的作者GitHub联合创始人Tom Preston-Werner 觉得YAML不够优雅，捣鼓出来的一个新格式。如果你不喜欢这种格式，你可以将config.toml替换为YAML格式的config.yaml，或者json格式的config.json。hugo都支持。&lt;br /&gt;
进行个人配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;baseurl = &amp;quot;http://slumber1122.github.io&amp;quot;
title = &amp;quot;長風無時&amp;quot;
languageCode = &amp;quot;en-us&amp;quot;
theme = &amp;quot;hugo-zen&amp;quot;
author = &amp;quot;wade van&amp;quot;
copyright = &amp;quot;wade van All rights reserved.&amp;quot;

[params]
  logo      = &amp;quot;/images/me.jpg&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;安装theme&#34;&gt;安装Theme&lt;/h3&gt;

&lt;p&gt;进入 mysite &lt;code&gt;$ cd mysite&lt;/code&gt;在&lt;a href=&#34;http://themes.gohugo.io/&#34;&gt;gohugo&lt;/a&gt;选择一个皮肤,&lt;br /&gt;
安装皮肤&lt;code&gt;$ git submodule add https://github.com/spf13/hyde themes/hyde&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;新建文章&#34;&gt;新建文章&lt;/h3&gt;

&lt;p&gt;content目录里放的是你写的markdown文章，layouts目录里放的是网站的模板文件，static目录里放的是一些图片、css、js等资源。&lt;/p&gt;

&lt;p&gt;创建一个about页面&lt;code&gt;$ hugo new about.md&lt;/code&gt;
如果是博客日志，最好将md文件放在content的post目录里。&lt;br /&gt;
&lt;code&gt;$ hugo new post/first.md&lt;/code&gt;
执行完后，会在content/post目录自动生成一个MarkDown格式的first.md文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+++
tags = [
  &amp;quot;hugo&amp;quot;,
  &amp;quot;github pages&amp;quot;,
]
title = &amp;quot;Hugo搭建Github Pages静态网站&amp;quot;
date = &amp;quot;2016-10-29T12:17:00+08:00&amp;quot;
slug = &amp;quot;&amp;quot;

+++
hello
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用markdown进行创作。&lt;/p&gt;

&lt;p&gt;在命令行执行，&lt;code&gt;hugo server -w&lt;/code&gt;， 可以在浏览器中访问&lt;code&gt;http://127.0.0.1:1313/hugo_blog/&lt;/code&gt;进行预览&lt;/p&gt;

&lt;h3 id=&#34;关联至github的个人页面&#34;&gt;关联至Github的个人页面&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;建立github-project-hugo repo (用來 host Hugo 的內容)&lt;/li&gt;
&lt;li&gt;建立your-github-account.github.io repo (个人静态网站)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将hugo repo link到刚才创建的hugo站点目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git init
$ git remote add git@githut.com/slumber1122/&amp;lt;github-project&amp;gt;-hugo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将个人静态网站link到public目录下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ rm -rf public
$ git submodule add git@github.com:&amp;lt;your-github-account&amp;gt;/&amp;lt;your-github-account&amp;gt;.github.io.git public
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;发布blog&#34;&gt;发布blog&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# deploy.sh
#!/bin/bash
echo -e &amp;quot;\033[0;32mDeploying updates to GitHub...\033[0m&amp;quot;
# Build the project.
hugo # if using a theme, replace by `hugo -t &amp;lt;yourtheme&amp;gt;`
# Go To Public folder
cd public
# Add changes to git.
git add -A
# Commit changes.
msg=&amp;quot;rebuilding site `date`&amp;quot;
if [ $# -eq 1 ]
  then msg=&amp;quot;$1&amp;quot;
fi
git commit -m &amp;quot;$msg&amp;quot;
# Push source and build repos.
git push origin master
# Come Back
cd ..

git add -A
msg=&amp;quot;backup blog site `date`&amp;quot;
git commit -m &amp;quot;$msg&amp;quot;
git push origin master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将deploy.sh新增至站点目录下，执行&lt;code&gt;$ ./deploy.sh &amp;quot;you commit message&amp;quot;&lt;/code&gt;便可将內容推送到 &lt;your-github-account&gt;-hugo，而 public被推送到 &lt;your-github-account&gt;.github.io上。&lt;/p&gt;

&lt;h3 id=&#34;站点目录结构&#34;&gt;站点目录结构&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;├── LICENSE
├── README.md
├── config.toml
├── content
│   └── posts
│       ├── Structuring_Python_Project.md
│       ├── first-post.md
│       └── neural_net.md
├── deploy.sh
├── posthelper.sh
├── public
├── static
│   └── images
│       └── me.jpg
└── themes
    └── hugo-zen
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;参考资料&#34;&gt;参考资料&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://kaichu.io/2015/07/12/my-first-post/&#34;&gt;在 Github Pages 建立 Hugo 靜態網站&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
